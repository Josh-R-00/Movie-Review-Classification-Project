{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification for Movie Reviews\n",
    "\n",
    "## Goal\n",
    "\n",
    "With this project, we aimed to use the machine learning skills in this class and apply it to a popular field in machine learning: text classification. We found a great dataset that put together 50,000 movie reviews for binary classification based on whether the movie review was positive or negative. This is useful for websites that serve as aggregates for movie reviews, such as Rotten tomatoes, as users can submit their reviews. \n",
    "\n",
    "The notebook is self contained and shares all the results for understanding, but should one want to run the code for themselves, here is the github link where our data lives.\n",
    "\n",
    "https://github.com/Deionus/345-final\n",
    "\n",
    "## Step 0: The Data and Procedure\n",
    "\n",
    "The dataset comes from an article titled *Learning Word Vectors for Sentiment Analysis* written by Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. It is very robust which will make it incredibly useful as large data sets help the accuracy of our classifier. It includes the text files of the 50,000 reviews along with some other processed data.\n",
    "\n",
    "Furthermore, Miguel Fern√°ndez Zafra wrote an article titled *Text Classification in Python* that was helpful in explaining what natural language processing entailed and how machine learning fits in. The implementation and procedure was made on our own, but it gave us some useful ideas to consider for natural language processing as a whole.\n",
    "\n",
    "Link to article: https://towardsdatascience.com/text-classification-in-python-dd95d264c802\n",
    "\n",
    "## Step 1: Feature Exploration\n",
    "\n",
    "The dataset divided the reviews into 25,000 positive reviews and 25,000 negative reviews split evenly into training and test sets. Furthermore, the creators of the dataset turned each review into a tokenized bag of words that matches with a vocab set. The vocab set list has every words that comes up in the review set and maps it to a number. However, there are still a few things we needed to do to get the data ready for classification.\n",
    "\n",
    "## Step 2: Text Clean-Up and Transformation\n",
    "\n",
    "While the bag of words is a great start, the word count doesn't give the whole story. We want to better represent the words by representing not only the word count in the review but how relative it is in document frequency (A word that appears in every document is not as useful as a word that only appears in positive movies for example. We will achieve this by using a tf-idf (term frequency to inverse document frequency) score which we will then vectorize to use for classification. While scikit-learn has a tdf function, it doesn't work with the bag of words given in the data, hence why we wrote our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Finding the frequency of each term\n",
    "\n",
    "vocab = open(\"aclImdb/imdb.vocab\", errors='ignore').read().splitlines()\n",
    "trainReviews = open(\"aclImdb/train/labeledBow.feat\").read().splitlines()\n",
    "testReviews = open(\"aclImdb/test/labeledBow.feat\").read().splitlines()\n",
    "docFreqTrain = [0] * len(vocab)\n",
    "\n",
    "for line in trainReviews:\n",
    "    bag = line.split()\n",
    "    bag.pop(0)\n",
    "    for word in bag:\n",
    "        pair = word.split(\":\")\n",
    "        docFreqTrain[int(pair[0])] += 1 \n",
    "\n",
    "# Calculating tf-idf score for standardizing\n",
    "\n",
    "def TF_score(pair):\n",
    "    left = int(pair[0])\n",
    "    right = int(float(pair[1]))\n",
    "    return right * math.log(25000/int(docFreqTrain[left]))\n",
    "\n",
    "def getFile(reviews, score):\n",
    "    updatedReviews = \"\"\n",
    "    for line in reviews:\n",
    "        bag = line.split()\n",
    "        updateLine = \"0 \" if (int(bag.pop(0)) <= 4) else \"1 \"\n",
    "        for word in bag:\n",
    "            pair = word.split(\":\")\n",
    "            updateLine += pair[0]\n",
    "            updateLine += \":\"\n",
    "            updateLine += str(score(pair))\n",
    "            updateLine += \" \"\n",
    "        updateLine += \"\\n\"\n",
    "        updatedReviews += updateLine\n",
    "    return updatedReviews\n",
    "\n",
    "updatedReviewsTrain = getFile(trainReviews, TF_score)\n",
    "updatedReviewsTest = getFile(testReviews, TF_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will vectorize and turn the data into an array. We will treat each word in the vocab as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 89527) (25000,)\n",
      "(25000, 89527) (25000,)\n"
     ]
    }
   ],
   "source": [
    "TrainData = updatedReviewsTrain.splitlines()\n",
    "TestData = updatedReviewsTest.splitlines()\n",
    "\n",
    "TrainFeatures = np.zeros((len(TrainData), len(vocab)))\n",
    "TrainLabels = np.zeros(len(TrainData))\n",
    "TestFeatures = np.zeros((len(TestData), len(vocab)))\n",
    "TestLabels = np.zeros(len(TestData))\n",
    "\n",
    "for i in range(0, len(TrainData)):\n",
    "    bag = TrainData[i].split()\n",
    "    TrainLabels[i] = int(bag.pop(0))\n",
    "    for word in bag:\n",
    "        pair = word.split(\":\")\n",
    "        TrainFeatures[i][int(pair[0])] = float(pair[1])\n",
    "\n",
    "for i in range(0, len(TestData)):\n",
    "    bag = TestData[i].split()\n",
    "    TestLabels[i] = int(bag.pop(0))\n",
    "    for word in bag:\n",
    "        pair = word.split(\":\")\n",
    "        TestFeatures[i][int(pair[0])] = float(pair[1])\n",
    "        \n",
    "print(TrainFeatures.shape, TrainLabels.shape)\n",
    "print(TestFeatures.shape, TestLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, just to see how the data perform without any optimization, we'll run it through a basic svm classifier and see how the accuracy is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(TrainFeatures, TrainLabels)\n",
    "\n",
    "print(\"Accuracy of Train Set: \", svc.score(TrainFeatures, TrainLabels), \"\\n\")\n",
    "print(\"Accuracy of Test Set: \", svc.score(TestFeatures, TestLabels))\n",
    "\n",
    "plot_confusion_matrix(svc, TestFeatures, TestLabels, cmap=plt.cm.Blues, values_format='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier has decent accuracy on the test, but as we can see when compared to the acurracy of the Train Set, we may have some overfitting that is not well generalized for test data. We also need to do a more in depth process for classification to figure out which classifier is the best overall. This will be covered in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Further Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the Linear SVM classifier going to be the best classifier to use for this data? To figure this out, let's test three more classifiers for binary classification problems. First, the Multinomial Naive Bayes Classifier, then a standard Perceptron, and finally a Neural Network Multi-Layer Perceptron Classifier. Once we compare these classifiers at their default Scikit Learn settings, we'll take the most promising one and tune it's hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier works by assuming independence among the features, and using Bayes' theorem in the decision rule. This classifier is best for text classification when each feature is an integer, and in practice will also work using TF-IDF vectors. Since we're using TF-IDF scores for our features, we expect this classifier to be less accurate than the LinearSVC classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Set:  0.95504 \n",
      "\n",
      "Accuracy of Test Set:  0.76976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(TrainFeatures, TrainLabels)\n",
    "\n",
    "print(\"Accuracy of Train Set: \", nb.score(TrainFeatures, TrainLabels), \"\\n\")\n",
    "print(\"Accuracy of Test Set: \", nb.score(TestFeatures, TestLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, the MultinomialNB classifier is significantly less accurate than the LinearSVC classifier. It does not appear to be overfitting, but the test accuracy is not nearly as good as the test accuracy of the LinearSVC classifier.\n",
    "\n",
    "Now, we'll fit the data to a perceptron and see how the score weighs in. As we learned in class, the perceptron classifier is a binary classifier which makes a decision based on a vector of numbers. This is perfect for our classification, as we are only predicting whether a movie got a negative or positive review. If the test accuracy of the perceptron is 1, that means the training data is linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Set:  0.99952 \n",
      "\n",
      "Accuracy of Test Set:  0.8438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "percep = Perceptron()\n",
    "percep.fit(TrainFeatures, TrainLabels)\n",
    "\n",
    "print(\"Accuracy of Train Set: \", percep.score(TrainFeatures, TrainLabels), \"\\n\")\n",
    "print(\"Accuracy of Test Set: \", percep.score(TestFeatures, TestLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the initial test, Perceptron looks very promising! The accuracy of the Train set is very close to 1.0, meaning that the data is almost linearly separable. Since the accuracy on the training set is so close to 1.0, it's safe to assume that the LinearSVC classifier is not overfitting!\n",
    "\n",
    "Lets take it a step further and search for better hyperparameters. For this, we'll use Grid Seach Cross Validation with a parameter grid to test different hyperparameters. Ideally, we'd be able to do this with the entire dataset, but because of it's massive size we need to shrink it to only 5,000 training samples instead of 25,000. 2,500 will be positive reviews, and 2,500 will be negative reviews. Then, we'll use this reduced set in the Grid Search CV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 89527) (5000,)\n",
      "(5000, 89527) (5000,)\n"
     ]
    }
   ],
   "source": [
    "#Reduce training set to only 5000 data points to save RAM\n",
    "\n",
    "RTrainFeatures = TrainFeatures[10000:15000, :]\n",
    "RTestFeatures = TestFeatures[10000:15000, :]\n",
    "RTrainLabels = TrainLabels[10000:15000]\n",
    "RTestLabels = TestLabels[10000:15000]\n",
    "\n",
    "print(RTrainFeatures.shape, RTrainLabels.shape)\n",
    "print(RTestFeatures.shape, RTestLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 1000, 'tol': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#Grid Search CV with Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Focusing on the Tolerance and Max Iterations hyperparameters\n",
    "param_grid = {'tol': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "              'max_iter': [1000, 5000, 10000]}\n",
    "\n",
    "perceptron_tuning = GridSearchCV(Perceptron(), param_grid)\n",
    "\n",
    "perceptron_tuning.fit(RTrainFeatures, RTrainLabels)\n",
    "\n",
    "print(perceptron_tuning.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the recommended parameters on the full dataset and see if there is an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Set:  0.99972 \n",
      "\n",
      "Accuracy of Test Set:  0.8438\n"
     ]
    }
   ],
   "source": [
    "percep = Perceptron(tol=1e-1, max_iter=1000)\n",
    "percep.fit(TrainFeatures, TrainLabels)\n",
    "\n",
    "print(\"Accuracy of Train Set: \", percep.score(TrainFeatures, TrainLabels), \"\\n\")\n",
    "print(\"Accuracy of Test Set: \", percep.score(TestFeatures, TestLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the new hyperparameters marginally increased our accuracy on the traning set, but had no affect on the test set. And still, the LinearSVC classifier is marginally better. \n",
    "\n",
    "Next, we'll attempt to use a neural network. Lets use 5 hidden layers, each with 20 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Set:  1.0 \n",
      "\n",
      "Accuracy of Test Set:  0.8358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP = MLPClassifier(hidden_layer_sizes = (20,20,20,20,20))\n",
    "\n",
    "MLP.fit(TrainFeatures, TrainLabels)\n",
    "\n",
    "print(\"Accuracy of Train Set: \", MLP.score(TrainFeatures, TrainLabels), \"\\n\")\n",
    "print(\"Accuracy of Test Set: \", MLP.score(TestFeatures, TestLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of trying the Multi-Layer Perceptron Neural Network are very interesting, the accuracy of the train set is 1.0 (just like LinearSVC), however the accuracy on the test set is 1% lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the Linear SVC classifier is going to be the most accurate. Now, We'll attempt some hyperparameter optimization for the LinearSVC. Again, we'll have to use a reduced data set due to hardware limitations. However, since the accuracy and the training set is already so high, and overfitting doesn't seem to be taking place, it is unlikely that changing the hyperparameters will greatly increase our accuracy on the test set.\n",
    "\n",
    "The hyperparameters We'll test for are the Tolerance, Max Iterations, and C value.\n",
    "\n",
    "Tolerance: The tolerance for the stopping criteria. The higher the tolerance, the sooner the classifier will stop.\n",
    "\n",
    "Max Iterations: The maximum iterations the classifier will go through before stopping\n",
    "\n",
    "C: Regularization Parameter, Higher Value results in more complex decision curves. Lower value results in a smoother decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/deionus/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 10000, 'tol': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'tol': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "              'max_iter': [10000, 20000, 50000, 100000],\n",
    "              'C': [1.0, 2.0, 5.0, 10.0]}\n",
    "\n",
    "classifier = GridSearchCV(LinearSVC(), param_grid)\n",
    "\n",
    "classifier.fit(RTrainFeatures, RTrainLabels)\n",
    "\n",
    "print(classifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Set:  1.0 \n",
      "\n",
      "Accuracy of Test Set:  0.84776\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(max_iter=10000, tol=0.1, C=1.0)\n",
    "svc.fit(TrainFeatures, TrainLabels)\n",
    "\n",
    "print(\"Accuracy of Train Set: \", svc.score(TrainFeatures, TrainLabels), \"\\n\")\n",
    "print(\"Accuracy of Test Set: \", svc.score(TestFeatures, TestLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the accuracy on the training set improved by less 0.0001. Now let's test this classifier with some reviews of modern movies from IMDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE MODERN REVIEW TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a class that implements the LinearSVC classifier and simply prints whether or not a given review is positive or negative. We've collected a couple of reviews off of IMDb for popularly good and bad movies. The review chosen is the top review on the IMDb page for that movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperSmartMovieCritic():\n",
    "    def __init__(self):\n",
    "        self.svc = svc = LinearSVC(max_iter=10000, tol=0.1)\n",
    "    \n",
    "    def fit(self, TrainFeatures, TrainLabels):\n",
    "        self.svc.fit(TrainFeatures, TrainLabels)\n",
    "        \n",
    "    def predict(self, file_name):\n",
    "        bag = Tokenizer(file_name).split()\n",
    "        bag.pop(0)\n",
    "        datum = [[0] * len(vocab)]\n",
    "        for word in bag:\n",
    "            pair = word.split(\":\")\n",
    "            datum[0][int(pair[0])] = float(TF_score(pair))\n",
    "            \n",
    "        prediction = self.svc.predict(datum)\n",
    "        \n",
    "        if (prediction > 0):\n",
    "            return \"is good!\"\n",
    "        else:\n",
    "            return \"is bad!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = SuperSmartMovieCritic()\n",
    "\n",
    "critic.fit(TrainFeatures, TrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parasite is good!\n",
      "Blade Runner is good!\n",
      "Half Brothers is bad!\n",
      "Cats is bad!\n",
      "Dunkirk is good!\n",
      "Get Out is good!\n",
      "The Room is bad!\n",
      "Sharknado is bad!\n",
      "Shrek is good!\n",
      "Annihilation is good!\n"
     ]
    }
   ],
   "source": [
    "print(\"Parasite\", critic.predict(\"parasite.txt\")) # Expecting good\n",
    "print(\"Blade Runner\", critic.predict(\"blade_runner_2049.txt\")) # Expecting Good\n",
    "print(\"Half Brothers\", critic.predict(\"half_brothers.txt\")) # Expecting Bad\n",
    "print(\"Cats\", critic.predict(\"cats.txt\")) # Expecting Bad\n",
    "print(\"Dunkirk\", critic.predict(\"dunkirk.txt\")) # Expecting Good\n",
    "print(\"Get Out\", critic.predict(\"get_out.txt\")) # Expecting Good\n",
    "print(\"The Room\", critic.predict(\"the_room.txt\")) # Expecting Bad\n",
    "print(\"Sharknado\", critic.predict(\"sharknado.txt\")) # Expecting Bad \n",
    "print(\"Shrek\", critic.predict(\"shrek.txt\")) # Expecting Good\n",
    "print(\"Annihilation\", critic.predict(\"annihilation.txt\")) # Expecting Good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critic was able to correctly classify every movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOKENIZER\n",
    "\n",
    "This class takes in the File Name of a movie review and converts it into a Bag of Words using the imdb.vocab file.\n",
    "\n",
    "RETURNS a string with 0 at the front and a count of each word present afterwards, delimited by whitespace. No newline character at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def Tokenizer(file_name):\n",
    "    vocab = open(\"aclImdb/imdb.vocab\").read().splitlines()\n",
    "    \n",
    "    review = open(file_name).read()\n",
    "    allow = string.ascii_letters + string.whitespace + \"'-\"\n",
    "    review = re.sub('[^%s]' % allow, '', review).lower().split()\n",
    "    \n",
    "    word_count = {}\n",
    "    \n",
    "    for word in review:\n",
    "        count = review.count(word)\n",
    "        word_count[word] = count\n",
    "        \n",
    "    converted_word_count = {}\n",
    "    \n",
    "    for word, count in word_count.items():\n",
    "        try:\n",
    "            index = vocab.index(word)\n",
    "            converted_word_count[index] = count\n",
    "        except ValueError:    \n",
    "            continue\n",
    "            \n",
    "    indices = list(converted_word_count.keys())\n",
    "    indices.sort()\n",
    "    \n",
    "    sorted_bow = {}\n",
    "    \n",
    "    for index in indices:\n",
    "        sorted_bow[index] = converted_word_count[index]\n",
    "        \n",
    "    return_string = \"0 \"\n",
    "    \n",
    "    for index, count in sorted_bow.items():\n",
    "        return_string += str(index)\n",
    "        return_string += \":\"\n",
    "        return_string += str(count)\n",
    "        return_string += \" \"\n",
    "    \n",
    "    return return_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We were excited to find that our classifier was successful in classifying the reviews that we pulled in. The accuracy is generally high, but there's even more that we can do to boost the accuracy. While we did a lot of preprocessing on our end for the text files, there's still a degree to overfitting that could be accounted for. For example, words that have the same base could be accounted for with lemmatization and stemming. Furthermore, while the tf-idf frequency helped account for common words like stop words, it could help the processing become quicker if we removed them at all. Finally, we could explore beyond reviews and use the same procedures for classifying a movie based on genre for example.\n",
    "\n",
    "Natural Language Processing is becoming more and more popular as an incredibly useful tool with vast applications. We are excited to continue using the machine learning principles we've learned in this class to go even further in the world of machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}